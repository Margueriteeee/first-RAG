# 什么是RAG？
## 1.1 核心定义
RAG，全称为 Retrieval-Augmented Generation.

是一种解决大语言模型“知其然不知其所以然”问题的**技术范式**，核心是把模型内部学到的“参数化知识”和来自外部知识库的“非参数化知识”相结合。  
- 参数化知识：模型通过学习得到的权重，类似于人类大脑中模糊的记忆  
- 非参数化知识：来源于可靠的外部知识库，内容精确，是可随时更新的外部数据

运作逻辑：  
- 在LLM生成文本之前，先通过 **检索机制** 从外部知识库中动态地获取相关信息，并将这些参考资料融入文本生成的过程，提升输出文本的准确性和时效性

> RAG 就像给正在学习的小孩（模型）一个课本（外部知识库），让他学习到的内容是有依据的，可靠的

## 1.2 技术原理
RAG 实现两种知识的结合过程分为两个阶段：

1. 检索阶段：“寻找非参数化知识“  
   - 知识向量化：embedding， 把知识库里的内容编码为向量索引（转化为计算机可以处理的形式），存入一个**向量数据库**
   - 语义召回：根据用户发起的查询，对应的检索模块同样先把查询的**问题向量化**，通过**相似度搜索**，从向量数据库中锁定与问题向量最相关的文档片段

2. 生成阶段：两种知识的融合
   - 整合上下文：有一个生成模块，接受检索阶段输出的**相关文档片段**和用户的**原始问题**  
   - 生成引导指令：生成模块会遵循预先设置好的 **Prompt** 指令，将上下文与问题有效整合，然后引导对应的LLM进行文本生成，确保文本的可控和有理有据

## 1.3 技术演进分类
![Alt text](image.png)

演进的趋势基本上是：复杂度增加、模块化组合编排